#' Integration Multiple PLSKO with Aggregate Knockoffs (AKO) Procedure
#'
#' This function implements the Aggregate Knockoffs (AKO) procedure from Nguyen et al. (2020)  with knockoff variables generated by PLSKO, to address the randomness from single-run knockoffs and improve the stablity. It generates multiple knockoff copies from PLSKO, computes feature importance statistics, aggregates p-values across knockoff realisations to control the false discovery rate. Compared to single-run knockoffs, AKO improved the average power with FDR control. The function is adapted from Y Fan et al. (2019).
#'
#' @import knockoff
#' @import doParallel
#' @import foreach
#' @param X A numeric matrix or dataframe. The original predictor data matrix with \eqn{n} observations as rows and \eqn{p} variables as columns.
#' @param y A numeric vector of responses.
#' @param n_ko An integer specifying the number of knockoff copies to generate by PLSKO. Default is 25.
#' @param q A numeric value specifying the target false discovery rate (FDR). Default is 0.05.
#' @param offset An integer (0 or 1) specifying the offset in the empirical p-value calculation. Default is 1.
#' @param w.method A character string specifying the method to compute feature importance statistics. Default is \code{"lasso.lcd"}. Other options include \code{"lasso.logistic"} for binary response variable, \code{"lasso.max.lambda"} for the maximum lambda value for the first entry on the path, and \code{"RF"} for random forest.
#' @param gamma A numeric value between 0 and 1 for the quantile aggregation parameter. Default is 0.3.
#' @param seed An integer to set the random seed for reproducibility. Default is 1.
#' @param parallel Logical value indicating whether to run the process in parallel. Default is TRUE.
#' @param cores An integer specifying the number of cores to use for parallel processing. Default is NULL, which uses all available cores except one.
#' @param ... Additional arguments passed to the \link[=plsko]{plsko} knockoff-generating function.
#'
#' @return A list containing:
#' \describe{
#'   \item{\code{s}}{A list of selection results from each knockoff iteration.}
#'   \item{\code{ako.s}}{A vector of indices of variables selected after aggregation.}
#' }
#'
#' @examples
#' \dontrun{
#' set.seed(123)
#' X <- matrix(rnorm(100 * 10), 100, 10)
#' y <- rnorm(100)
#' result <- plsAKO(X, y)
#' }
#'
#' @references
#'
#' @export
#'
plsAKO <- function(X, y, n_ko = 25,
                q = 0.05, offset = 1, w.method = "lasso.lcd",
                gamma = 0.3, seed = 1, parallel = T, cores = NULL, ...){

  #Input type validation
  if(is.data.frame(X)){
    X.name = names(X)
    X = as.matrix(X)
  }else if (is.matrix(X)) {
    X.names = colnames(X)
  }else {
    stop('Input X must be a numeric matrix or data frame')
  }
  if (!is.numeric(X)) stop('Input X must be a numeric matrix or data frame')

  if (!is.factor(y) && !is.numeric(y)) {
    stop('Input y must be either of numeric or factor type')
  }
  if( is.numeric(y) ) y = as.vector(y)

  if(offset!=1 && offset!=0) {
    stop('Input offset must be either 0 or 1')
  }

  if (!w.method %in% c("lasso.lcd", "lasso.logistic", "lasso.max.lambda", "RF")) stop('Input w.method must be either "lasso.lcd", "lasso.logistic", "lasso.max.lambda" or "RF". Or check function "AKO.filter_withW" for advanced customised W input')

  # Check if the number of observations in X is equal to the length of y
  stopifnot(length(y) == nrow(X))

  set.seed(seed)
  # Initialize matrix to store p-values from each knockoff iteration
  pvals = matrix(0, ncol(X), n_ko)
  selected <- list()

  if(parallel){
    library(foreach)
    library(doParallel)
    cl <- ifelse(is.null(cores), detectCores()-1, cores)
    registerDoParallel(cl)

    foreach(i = 1:n_ko, .combine = 'c') %dopar% {
      set.seed(seed + i)
      # Generate PLSKO knockoff
      ko = plsko(X, ...)

      # Calculate the apply knokcoff filter
      S <- ko.filter(X = X, Xk = ko, y = y, q = q, method = w.method)

      pvals[,i] = empirical_pval(S$W, offset = offset)
      selected[i] <- S
    }
    stopImplicitCluster()
  }

  for (i in 1:n_ko) {
    set.seed(seed + i)
    # Generate PLSKO knockoff
    ko = plsko(X, ...)

    # Calculate the apply knokcoff filter
    S <- ko.filter(X = X, Xk = ko, y = y, q = q, method = w.method)

    pvals[,i] = empirical_pval(S$W, offset = offset)
    selected[i] <- S
  }

  aggregated_pval = apply(pvals, 1, quantile_aggregation, gamma=gamma)

  threshold = bhq_threshold(aggregated_pval, fdr=q)

  ako.s <- which(aggregated_pval <= threshold)

  return(list(s = selected,
              ako.s = ako.s
  ))
}


# AKO with generated knockoff sets as a list
AKO_withKO <- function(X, y, Xko.list,
                        q = 0.05,  w.method = "lasso.lcd", offset = 1,
                        gamma = 0.3, seed = 1){

  set.seed(seed)

  n_ko = length(Xko.list)
  pvals = matrix(0, ncol(X), n_ko)
  selected <- list()
  #Multiple Knockoffs
  for (i in 1:n_ko) {
    #print(i)

    ko <- Xko.list[[i]]

    S <- ko.filter(X = X, Xk = ko, y = y, q = q, method = w.method)

    pvals[,i] = empirical_pval(S$W, offset = offset)
    selected[i] <- S
  }

  aggregated_pval = apply(pvals, 1, quantile_aggregation, gamma=gamma)

  threshold = bhq_threshold(aggregated_pval, fdr=q)

  ako.s <- which(aggregated_pval <= threshold)

  return(list(s = selected,
              ako.s = ako.s
  ))
}

AKO_withW <- function(W, q = 0.05, offset = 1, gamma = 0.3){

  p = length(W[[1]])
  n_ko = length(W)

  pvals = matrix(0, p, n_ko)
  selected <- list()
  #Multiple Knockoffs
  for (i in 1:n_ko) {}
    pvals[,i] = empirical_pval(W[[i]], offset = offset)
    selected[i] <- S
  }

  aggregated_pval = apply(pvals, 1, quantile_aggregation, gamma=gamma)

  threshold = bhq_threshold(aggregated_pval, fdr=q)

  ako.s <- which(aggregated_pval <= threshold)

  return(list(s = selected,
              ako.s = ako.s
  ))
}

empirical_pval = function(test_score, offset = 1){
  pvals = c()
  n_features = length(test_score)
  if (offset !=0 && offset!=1){
    return("'offset' must be either 0 or 1")
  }
  else{
    test_score_inv = -test_score
    for (i in 1:n_features){
      if (test_score[i] <= 0){
        pvals = c(pvals, 1)
      }
      else{

        pvals = c(pvals,(offset+sum(test_score_inv[i] >= test_score))/n_features)
      }
    }
  }
  return (pvals)
}

quantile_aggregation = function(pvals, gamma=0.3){
  converted_score = (1 / gamma) *  quantile(pvals, gamma)
  return (min(1, converted_score))
}

bhq_threshold = function(pvals, fdr=0.1){
  n_features = length(pvals)
  pvals_sorted = sort(pvals)
  selected_index = 2 * n_features
  for (i in seq(n_features, 1, -1)){
    if (pvals_sorted[i] <= (fdr * i / n_features)){
      selected_index = i
      break
    }
  }
  if (selected_index <= n_features){
    return (pvals_sorted[selected_index])
  }
  else{
    return ('-1.0')
  }
}
